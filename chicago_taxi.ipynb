{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM0L6gsRjBRE1aDi5UDqinL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abidjahan1/citytaxi_linear_regression/blob/main/chicago_taxi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "cellView": "form",
        "id": "3PBA2YdRABNh"
      },
      "outputs": [],
      "source": [
        "#@title Required libraries\n",
        "!pip install keras~=3.8.0 \\\n",
        "  matplotlib~=3.10.0 \\\n",
        "  numpy~=2.0.0 \\\n",
        "  pandas~=2.2.0 \\\n",
        "  tensorflow~=2.18.0\n",
        "\n",
        "print('\\n\\nAll requirements successfully installed.')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load dependencies\n",
        "#general\n",
        "import io\n",
        "\n",
        "# data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# machine learning\n",
        "import keras\n",
        "\n",
        "# data visualization\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "cellView": "form",
        "id": "HDrvdp-OAUv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Load dataset & Read dataset\n",
        "chicago_taxi_dataset = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/chicago_taxi_train.csv\")\n",
        "chicago_taxi_dataset.head()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Ist3HSI4A6hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Code - Updates dataframe\n",
        "\n",
        "# Updates dataframe to use specific columns.\n",
        "training_df = chicago_taxi_dataset[['TRIP_MILES', 'TRIP_SECONDS', 'FARE', 'COMPANY', 'PAYMENT_TYPE', 'TIP_RATE']]\n",
        "\n",
        "print('Read dataset completed successfully.')\n",
        "print('Total number of rows: {0}\\n\\n'.format(len(training_df.index)))\n",
        "training_df.head(200)"
      ],
      "metadata": {
        "collapsed": true,
        "cellView": "form",
        "id": "oR1hBhBlBWiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Code - View dataset statistics\n",
        "\n",
        "print('Total number of rows: {0}\\n\\n'.format(len(training_df.index)))\n",
        "training_df.describe(include='all')"
      ],
      "metadata": {
        "id": "saVSuHhNBjcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Dataset statistics\n",
        "#  maximum fare\n",
        "max_fare = training_df['FARE'].max()\n",
        "print(\"the maximum fare? \\t\\t\\t\\tAnswer: ${fare:.2f}\".format(fare = max_fare))\n",
        "\n",
        "# the mean distance across all trips\n",
        "mean_distance = training_df['TRIP_MILES'].mean()\n",
        "print(\"the mean distance across all trips \\t\\tAnswer: {mean:.4f} miles\".format(mean = mean_distance))\n",
        "\n",
        "# numbers of cab companies are in the dataset\n",
        "num_unique_companies =  training_df['COMPANY'].nunique()\n",
        "print(\"cab companies are in the dataset \\t\\tAnswer: {number}\".format(number = num_unique_companies))\n",
        "\n",
        "# the most frequent payment type\n",
        "most_freq_payment_type = training_df['PAYMENT_TYPE'].value_counts().idxmax()\n",
        "print(\"most frequent payment type \\t\\t        Answer: {type}\".format(type = most_freq_payment_type))\n",
        "\n",
        "# features missing data\n",
        "missing_values = training_df.isnull().sum().sum()\n",
        "print(\"features missing data \\t\\t\\t\\tAnswer:\", \"No\" if missing_values == 0 else \"Yes\")"
      ],
      "metadata": {
        "id": "3yKPTKiLCyPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Code - View correlation matrix\n",
        "training_df.corr(numeric_only=True)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "qx7Ddp_TEHss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Code - View pairplot\n",
        "sns.pairplot(training_df, x_vars=[\"FARE\", \"TRIP_MILES\", \"TRIP_SECONDS\"], y_vars=[\"FARE\", \"TRIP_MILES\", \"TRIP_SECONDS\"])"
      ],
      "metadata": {
        "collapsed": true,
        "cellView": "form",
        "id": "BBGnAXL1GgFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lDW2mUwyHwKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EE7nBxoMUtE9"
      },
      "outputs": [],
      "source": [
        "#@title Define plotting functions\n",
        "\n",
        "def make_plots(df, feature_names, label_name, model_output, sample_size=200):\n",
        "\n",
        "  random_sample = df.sample(n=sample_size).copy()\n",
        "  random_sample.reset_index()\n",
        "  weights, bias, epochs, rmse = model_output\n",
        "\n",
        "  is_2d_plot = len(feature_names) == 1\n",
        "  model_plot_type = \"scatter\" if is_2d_plot else \"surface\"\n",
        "  fig = make_subplots(rows=1, cols=2,\n",
        "                      subplot_titles=(\"Loss Curve\", \"Model Plot\"),\n",
        "                      specs=[[{\"type\": \"scatter\"}, {\"type\": model_plot_type}]])\n",
        "\n",
        "  plot_data(random_sample, feature_names, label_name, fig)\n",
        "  plot_model(random_sample, feature_names, weights, bias, fig)\n",
        "  plot_loss_curve(epochs, rmse, fig)\n",
        "\n",
        "  fig.show()\n",
        "  return\n",
        "\n",
        "def plot_loss_curve(epochs, rmse, fig):\n",
        "  curve = px.line(x=epochs, y=rmse)\n",
        "  curve.update_traces(line_color='#ff0000', line_width=3)\n",
        "\n",
        "  fig.append_trace(curve.data[0], row=1, col=1)\n",
        "  fig.update_xaxes(title_text=\"Epoch\", row=1, col=1)\n",
        "  fig.update_yaxes(title_text=\"Root Mean Squared Error\", row=1, col=1, range=[rmse.min()*0.8, rmse.max()])\n",
        "\n",
        "  return\n",
        "\n",
        "def plot_data(df, features, label, fig):\n",
        "  if len(features) == 1:\n",
        "    scatter = px.scatter(df, x=features[0], y=label)\n",
        "  else:\n",
        "    scatter = px.scatter_3d(df, x=features[0], y=features[1], z=label)\n",
        "\n",
        "  fig.append_trace(scatter.data[0], row=1, col=2)\n",
        "  if len(features) == 1:\n",
        "    fig.update_xaxes(title_text=features[0], row=1, col=2)\n",
        "    fig.update_yaxes(title_text=label, row=1, col=2)\n",
        "  else:\n",
        "    fig.update_layout(scene1=dict(xaxis_title=features[0], yaxis_title=features[1], zaxis_title=label))\n",
        "\n",
        "  return\n",
        "\n",
        "def plot_model(df, features, weights, bias, fig):\n",
        "  df['FARE_PREDICTED'] = bias[0]\n",
        "\n",
        "  for index, feature in enumerate(features):\n",
        "    df['FARE_PREDICTED'] = df['FARE_PREDICTED'] + weights[index][0] * df[feature]\n",
        "\n",
        "  if len(features) == 1:\n",
        "    model = px.line(df, x=features[0], y='FARE_PREDICTED')\n",
        "    model.update_traces(line_color='#ff0000', line_width=3)\n",
        "  else:\n",
        "    z_name, y_name = \"FARE_PREDICTED\", features[1]\n",
        "    z = [df[z_name].min(), (df[z_name].max() - df[z_name].min()) / 2, df[z_name].max()]\n",
        "    y = [df[y_name].min(), (df[y_name].max() - df[y_name].min()) / 2, df[y_name].max()]\n",
        "    x = []\n",
        "    for i in range(len(y)):\n",
        "      x.append((z[i] - weights[1][0] * y[i] - bias[0]) / weights[0][0])\n",
        "\n",
        "    plane=pd.DataFrame({'x':x, 'y':y, 'z':[z] * 3})\n",
        "\n",
        "    light_yellow = [[0, '#89CFF0'], [1, '#FFDB58']]\n",
        "    model = go.Figure(data=go.Surface(x=plane['x'], y=plane['y'], z=plane['z'],\n",
        "                                      colorscale=light_yellow))\n",
        "\n",
        "  fig.add_trace(model.data[0], row=1, col=2)\n",
        "\n",
        "  return\n",
        "\n",
        "def model_info(feature_names, label_name, model_output):\n",
        "  weights = model_output[0]\n",
        "  bias = model_output[1]\n",
        "\n",
        "  nl = \"\\n\"\n",
        "  header = \"-\" * 80\n",
        "  banner = header + nl + \"|\" + \"MODEL INFO\".center(78) + \"|\" + nl + header\n",
        "\n",
        "  info = \"\"\n",
        "  equation = label_name + \" = \"\n",
        "\n",
        "  for index, feature in enumerate(feature_names):\n",
        "    info = info + \"Weight for feature[{}]: {:.3f}\\n\".format(feature, weights[index][0])\n",
        "    equation = equation + \"{:.3f} * {} + \".format(weights[index][0], feature)\n",
        "\n",
        "  info = info + \"Bias: {:.3f}\\n\".format(bias[0])\n",
        "  equation = equation + \"{:.3f}\\n\".format(bias[0])\n",
        "\n",
        "  return banner + nl + info + nl + equation\n",
        "\n",
        "print(\"SUCCESS: defining plotting functions complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Code - Define ML functions\n",
        "\n",
        "def build_model(my_learning_rate, num_features):\n",
        "  \"\"\"Create and compile a simple linear regression model.\"\"\"\n",
        "  # Describe the topography of the model.\n",
        "  # The topography of a simple linear regression model\n",
        "  # is a single node in a single layer.\n",
        "  inputs = keras.Input(shape=(num_features,))\n",
        "  outputs = keras.layers.Dense(units=1)(inputs)\n",
        "  model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "  # Compile the model topography into code that Keras can efficiently\n",
        "  # execute. Configure training to minimize the model's mean squared error.\n",
        "  model.compile(optimizer=keras.optimizers.RMSprop(learning_rate=my_learning_rate),\n",
        "                loss=\"mean_squared_error\",\n",
        "                metrics=[keras.metrics.RootMeanSquaredError()])\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "def train_model(model, features, label, epochs, batch_size):\n",
        "  \"\"\"Train the model by feeding it data.\"\"\"\n",
        "\n",
        "  # Feed the model the feature and the label.\n",
        "  # The model will train for the specified number of epochs.\n",
        "  history = model.fit(x=features,\n",
        "                      y=label,\n",
        "                      batch_size=batch_size,\n",
        "                      epochs=epochs)\n",
        "\n",
        "  # Gather the trained model's weight and bias.\n",
        "  trained_weight = model.get_weights()[0]\n",
        "  trained_bias = model.get_weights()[1]\n",
        "\n",
        "  # The list of epochs is stored separately from the rest of history.\n",
        "  epochs = history.epoch\n",
        "\n",
        "  # Isolate the error for each epoch.\n",
        "  hist = pd.DataFrame(history.history)\n",
        "\n",
        "  # To track the progression of training, we're going to take a snapshot\n",
        "  # of the model's root mean squared error at each epoch.\n",
        "  rmse = hist[\"root_mean_squared_error\"]\n",
        "\n",
        "  return trained_weight, trained_bias, epochs, rmse\n",
        "\n",
        "\n",
        "def run_experiment(df, feature_names, label_name, learning_rate, epochs, batch_size):\n",
        "\n",
        "  print('INFO: starting training experiment with features={} and label={}\\n'.format(feature_names, label_name))\n",
        "\n",
        "  num_features = len(feature_names)\n",
        "\n",
        "  features = df.loc[:, feature_names].values\n",
        "  label = df[label_name].values\n",
        "\n",
        "  model = build_model(learning_rate, num_features)\n",
        "  model_output = train_model(model, features, label, epochs, batch_size)\n",
        "\n",
        "  print('\\nSUCCESS: training experiment complete\\n')\n",
        "  print('{}'.format(model_info(feature_names, label_name, model_output)))\n",
        "  make_plots(df, feature_names, label_name, model_output)\n",
        "\n",
        "  return model\n",
        "\n",
        "print(\"SUCCESS: defining linear regression functions complete.\")"
      ],
      "metadata": {
        "id": "M8DV9AQiHVUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Train a model with one feature\n",
        "\n",
        "# The following variables are the hyperparameters.\n",
        "learning_rate = 0.001\n",
        "epochs = 20\n",
        "batch_size = 50\n",
        "\n",
        "# Specify the feature and the label.\n",
        "features = ['TRIP_MILES']\n",
        "label = 'FARE'\n",
        "\n",
        "model_1 = run_experiment(training_df, features, label, learning_rate, epochs, batch_size)"
      ],
      "metadata": {
        "id": "EKk55TmK87Ih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Train a model with two features\n",
        "\n",
        "# The following variables are the hyperparameters.\n",
        "learning_rate = 0.001\n",
        "epochs = 20\n",
        "batch_size = 50\n",
        "\n",
        "training_df.loc[:, 'TRIP_MINUTES'] = training_df['TRIP_SECONDS']/60\n",
        "\n",
        "features = ['TRIP_MILES', 'TRIP_MINUTES']\n",
        "label = 'FARE'\n",
        "\n",
        "model_2 = run_experiment(training_df, features, label, learning_rate, epochs, batch_size)"
      ],
      "metadata": {
        "id": "zsSwt8kZ9OtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Code - Define functions to make predictions\n",
        "def format_currency(x):\n",
        "  return \"${:.2f}\".format(x)\n",
        "\n",
        "def build_batch(df, batch_size):\n",
        "  batch = df.sample(n=batch_size).copy()\n",
        "  batch.set_index(np.arange(batch_size), inplace=True)\n",
        "  return batch\n",
        "\n",
        "def predict_fare(model, df, features, label, batch_size=50):\n",
        "  batch = build_batch(df, batch_size)\n",
        "  predicted_values = model.predict_on_batch(x=batch.loc[:, features].values)\n",
        "\n",
        "  data = {\"PREDICTED_FARE\": [], \"OBSERVED_FARE\": [], \"L1_LOSS\": [],\n",
        "          features[0]: [], features[1]: []}\n",
        "  for i in range(batch_size):\n",
        "    predicted = predicted_values[i][0]\n",
        "    observed = batch.at[i, label]\n",
        "    data[\"PREDICTED_FARE\"].append(format_currency(predicted))\n",
        "    data[\"OBSERVED_FARE\"].append(format_currency(observed))\n",
        "    data[\"L1_LOSS\"].append(format_currency(abs(observed - predicted)))\n",
        "    data[features[0]].append(batch.at[i, features[0]])\n",
        "    data[features[1]].append(\"{:.2f}\".format(batch.at[i, features[1]]))\n",
        "\n",
        "  output_df = pd.DataFrame(data)\n",
        "  return output_df\n",
        "\n",
        "def show_predictions(output):\n",
        "  header = \"-\" * 80\n",
        "  banner = header + \"\\n\" + \"|\" + \"PREDICTIONS\".center(78) + \"|\" + \"\\n\" + header\n",
        "  print(banner)\n",
        "  print(output)\n",
        "  return"
      ],
      "metadata": {
        "id": "VCc56mTy9cAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Code - Make predictions\n",
        "\n",
        "output = predict_fare(model_2, training_df, features, label)\n",
        "show_predictions(output)"
      ],
      "metadata": {
        "id": "OTqpBL2B9e0Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}